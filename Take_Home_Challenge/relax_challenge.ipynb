{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagement_path = '/Users/babyhandzzz/Desktop/ELEPH@NT/Datasets/relax_challenge/takehome_user_engagement.csv'\n",
    "users_path = '/Users/babyhandzzz/Desktop/ELEPH@NT/Datasets/relax_challenge/takehome_users.csv'\n",
    "users = pd.read_csv(users_path,encoding='ISO-8859-1',parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_engagement(path):\n",
    "    df = pd.read_csv(path, infer_datetime_format=True)\n",
    "    df['time_stamp'] = pd.to_datetime(df.time_stamp)    \n",
    "    df['date'] = df['time_stamp'].dt.date\n",
    "    df.set_index('time_stamp',inplace=True)\n",
    "    return df\n",
    "    \n",
    "user_engagement = load_user_engagement(user_engagement_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating labels for user calssification\n",
    "\n",
    "* How to find out if the user is \"adopted\" or not?\n",
    "* \"Defining an 'adopted user' as a user who has logged into the product on three separate days in at least one seven-Â­day period...\"\n",
    "\n",
    "1.After going through the data it looks like there are no instances of multiple logins on a single day. \n",
    "\n",
    "2.This means that one day in observations correlates to exactly one login.\n",
    "\n",
    "3.So the data can be aggregated with pandas resample (count) method on a 7 days basis. \n",
    "\n",
    "4.The resulting aggregation has counts of all logins per any 7-day period.\n",
    "\n",
    "5.If any one of those periods has a count of 3 or more, the user is considred to be \"adopted\". (According to the definition from the assignment pdf)\n",
    "\n",
    "Output list below proves that any given day only has one login recorded.\n",
    "Number of unique dates for one user is equal to number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ True]\n"
    }
   ],
   "source": [
    "list_ = []\n",
    "\n",
    "for i in unique_id:\n",
    "    df = user_engagement[user_engagement.user_id==i]\n",
    "    true_false = len(df.date.unique()) == df.shape[0] \n",
    "    list_.append(true_false)\n",
    "\n",
    "print(np.unique(np.array(list_)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually generating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_status_table():\n",
    "    \n",
    "    user_id = []\n",
    "    target = []\n",
    "    unique_id = np.unique(np.array(user_engagement.user_id)) # all of the unique users' ids\n",
    "\n",
    "    for user in unique_id:\n",
    "    \n",
    "        user_id.append(user)\n",
    "\n",
    "        logins = user_engagement[user_engagement.user_id==user].resample('7D').count()\n",
    "        logins = logins['visited']\n",
    "        \n",
    "        if len(logins)>1:\n",
    "            logins = max(logins)\n",
    "            if logins >= 3:\n",
    "                target.append(1) # append 1 if any given 7 day period has 3 logins\n",
    "            else:\n",
    "                target.append(0) # append 0 if there are no 3 logins within any number of 7-day activity periods\n",
    "        else:\n",
    "            target.append(0) # append 0 if there are not enough days for a 7-day period construction\n",
    "        \n",
    "        label_df = pd.DataFrame({'object_id':user_id, 'label':target})\n",
    "        \n",
    "    return label_df\n",
    "\n",
    "label_df = generate_user_status_table()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What fraction of users is engaging with the service?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fraction of users that logged-in at least once: 0.73525\n"
    }
   ],
   "source": [
    "#What fraction of users had at least one login?:\n",
    "print(\"Fraction of users that logged-in at least once: {}\".format(label_df.shape[0]/users.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0.83407\n1    0.16593\nName: label, dtype: float64"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "#Out of those users who had at least one login, what fraction is classified as \"adopted\"/\"not adopted\"?\n",
    "\n",
    "#0 - user is not adopted\n",
    "#1 - user is adopted \"\"\"\n",
    "\n",
    "label_df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe that contains users and labels\n",
    "labeled_users = label_df.merge(users,on='object_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparig the resulting dataframe for modeling:\n",
    "\n",
    "1. Dropping:\n",
    "    * creation_time\n",
    "    * name \n",
    "    * email \n",
    "    * last_session_creation_time\n",
    "\n",
    "2. Encodind:\n",
    "    * creation_source - one-hot\n",
    "    * org_id - one-hot\n",
    "    * ivited_by_user_id - binary\n",
    "\n",
    "3. Already encoded features:\n",
    "    * opted_in_to_mailing_list\n",
    "    * enabled_for_marketing_drip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [ 'creation_source', 'org_id', 'opted_in_to_mailing_list','enabled_for_marketing_drip','invited_by_user_id', 'label']\n",
    "labeled_users = labeled_users[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_ml(df):\n",
    "    # was a user invited or not? (if user is not invited there is a NaN)\n",
    "    df['invited_by_user_id'].fillna(0,inplace=True)\n",
    "    df['invited_by_user_id'] = np.where(df['invited_by_user_id'] == 0, 0, 1)\n",
    "    # \n",
    "    ohe_org_id = pd.get_dummies(df['org_id'],drop_first=True)\n",
    "    # how can I decrease memory use here? deleting dataframes?\n",
    "    ohe_creation_source = pd.get_dummies(df['creation_source'],drop_first=True)\n",
    "    df = pd.concat([ohe_org_id,ohe_creation_source, df[df.columns[2:]]],axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "ml_data = prepare_data_for_ml(labeled_users)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ml_data[[ml_data.columns[-1]]]\n",
    "X = ml_data[ml_data.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GradientBoostingClassifier()"
     },
     "metadata": {},
     "execution_count": 243
    }
   ],
   "source": [
    "xgb = GradientBoostingClassifier(n_estimators=100,max_depth=3)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train score: 0.8418203349687025\nTest score: 0.8241758241758241\nClassification Report\n              precision    recall  f1-score   support\n\n           0       0.83      0.99      0.90      2412\n           1       0.17      0.01      0.01       500\n\n    accuracy                           0.82      2912\n   macro avg       0.50      0.50      0.46      2912\nweighted avg       0.71      0.82      0.75      2912\n\n"
    }
   ],
   "source": [
    "train_score = xgb.score(X_train,y_train)\n",
    "test_score = xgb.score(X_test,y_test)\n",
    "\n",
    "print('Train score: {}'.format(train_score))\n",
    "print('Test score: {}'.format(test_score))\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is a huge class imbalance, next step is to find a work around it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594973088085",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}