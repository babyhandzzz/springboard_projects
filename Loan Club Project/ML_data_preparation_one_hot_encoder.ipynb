{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dtale\n",
    "#from caimcaim import CAIMD # https://github.com/airysen/caimcaim \n",
    "# not working for me.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder\n",
    "\n",
    "\n",
    "# Display options\n",
    "\n",
    "%matplotlib\n",
    "%matplotlib inline\n",
    "#pd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\n",
    "pd.options.display.float_format = '{:.4f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00\n",
    "pd.set_option('display.max_columns', 100) #  display all the columns\n",
    "pd.set_option('display.max_rows', 100) # display all the rows\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to be used later in the code.\n",
    "\n",
    "\n",
    "def less_than_1pct_cat_replace(df,pct=0.01):\n",
    "    \"\"\"\n",
    "    Replace all the categorical values who's proportion\n",
    "    is less than pct with 'other'.\n",
    "    \"\"\"\n",
    "\n",
    "    for column in df.columns:\n",
    "        selection = df[column].value_counts(normalize=True)<pct\n",
    "        list_to_replace = selection[selection==True].index\n",
    "        mask = df[column].isin(list_to_replace)\n",
    "        df[column][mask] = 'other'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def outlier_replacer(df):\n",
    "    \"\"\"\n",
    "    Replace all the outliers in a numerical df using \n",
    "    IQR methodology.\n",
    "    \n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        quartile_1, quartile_3 = np.percentile(df[column], [25, 75])\n",
    "        iqr = quartile_3 - quartile_1\n",
    "        lower_bound = quartile_1 - (float(iqr) * 1.5)\n",
    "        upper_bound = quartile_3 + (float(iqr) * 1.5)\n",
    "        df.loc[(df[column]<lower_bound) | (df[column] > upper_bound),[column]] = df[column].median()\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_single_unique_values(dataframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Drop all the columns that only contain one unique value.\n",
    "    not optimized for categorical features yet.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cols_to_drop = dataframe.nunique()\n",
    "    cols_to_drop = cols_to_drop.loc[cols_to_drop.values==1].index\n",
    "    dataframe = dataframe.drop(cols_to_drop,axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is loaded\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "df = pd.read_csv('Data/2nd_clean.csv')\n",
    "print('df is loaded')\n",
    "df.drop(['Unnamed: 0','issue_d','earliest_cr_line','last_pymnt_d',\n",
    "        'last_credit_pull_d'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any observation with the loan status 'current' has no value for the analysis as there is no way of knowing for sure the outcome of a loan. Similarlry other cases of status such as 'Does not meet the credit policy. Status:Fully Paid', 'Does not meet the credit policy. Status:Charged Off', 'Default' have been classified accordingly to their outocme, to reduce data sparcity. So those observations are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             1041952\n",
       "Charged Off                                             261655\n",
       "In Grace Period                                           8952\n",
       "Does not meet the credit policy. Status:Fully Paid        1988\n",
       "Does not meet the credit policy. Status:Charged Off        761\n",
       "Default                                                     31\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.loan_status!='Current']\n",
    "df = df[df.loan_status!='Late (31-120 days)']\n",
    "df = df[df.loan_status!='Late (16-30 days)']\n",
    "df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].replace(\n",
    "    {'Does not meet the credit policy. Status:Fully Paid':'Fully Paid',\n",
    "    'Does not meet the credit policy. Status:Charged Off':'Charged Off',\n",
    "    'Default':'Charged Off'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid         1043940\n",
       "Charged Off         262447\n",
       "In Grace Period       8952\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating categorical part of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:9114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# splitting the df into categorical and numerical parts\n",
    "ctgrcl_df = df.select_dtypes(include=['object'])\n",
    "nmrcl_df = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# have to drop the y feature\n",
    "ctgrcl_df.drop(['loan_status'],axis='columns',inplace=True)\n",
    "\n",
    "ctgrcl_df.fillna('other',inplace=True)\n",
    "\n",
    "# '<,>,+' have to be replaced for correct working of get_dummies function\n",
    "emp_lengthdict = {'10+ years':'ten years or more', \n",
    " '2 years':'two years', \n",
    " '< 1 year':'less than a year', \n",
    " '3 years':'three years', \n",
    " 'other':'other', \n",
    " '1 year':'one year',\n",
    " '5 years':'five years', \n",
    " '4 years':'four years', \n",
    " '6 years':'six years', \n",
    " '7 years':'seven years', \n",
    " '8 years':'eight years', \n",
    " '9 years':'nine years'}\n",
    "\n",
    "ctgrcl_df.emp_length.replace(emp_lengthdict,inplace=True)\n",
    "ctgrcl_df = less_than_1pct_cat_replace(ctgrcl_df,pct=0.01)\n",
    "\n",
    "# now the categorical part of the df is ready for train_test_split\n",
    "# stiching categorical and numerical data together\n",
    "df = pd.concat([nmrcl_df,ctgrcl_df,df[['loan_status']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data, dropping features with single uniqu values\n",
    "\n",
    "y = df[['loan_status']]\n",
    "X = df.drop('loan_status',axis='columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data into categorical and numerical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing training and testing data into categorical and numerical parts\n",
    "ctgrcl_X_train = X_train.select_dtypes(include=['object'])\n",
    "nmrcl_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "\n",
    "ctgrcl_X_test = X_test.select_dtypes(include=['object'])\n",
    "nmrcl_X_test = X_test.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 64)\n",
      "(328835, 64)\n"
     ]
    }
   ],
   "source": [
    "print(nmrcl_X_train.shape)\n",
    "print(nmrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating numerical X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation and outlier treatment - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (8) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 27 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 32 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 39 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discretization - done\n",
      "rescaling - done\n",
      "numerical data is ready\n"
     ]
    }
   ],
   "source": [
    "# imputation and outlier treatment (median, IQR)\n",
    "nmrcl_X_train = nmrcl_X_train.fillna(nmrcl_X_train.median())\n",
    "\n",
    "nmrcl_X_train = outlier_replacer(nmrcl_X_train)\n",
    "nmrcl_X_train = remove_single_unique_values(nmrcl_X_train)\n",
    "nmrcl_X_train_columns = nmrcl_X_train.columns\n",
    "X_train_median_values = nmrcl_X_train.median()\n",
    "\n",
    "print('imputation and outlier treatment - done')\n",
    "\n",
    "# This is a sub-optimal, temporary measure, as I haven't figured out \n",
    "# how to do supervised discretization.\n",
    "discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='kmeans')\n",
    "discretized_X_train = discretizer.fit_transform(nmrcl_X_train)\n",
    "\n",
    "print('discretization - done')\n",
    "\n",
    "# Min_max\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "rescaled_discretized_X_train = scaler.fit_transform(np.array(discretized_X_train))\n",
    "\n",
    "print('rescaling - done')\n",
    "print('numerical data is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating numerical X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation and outlier treatment - done\n",
      "discretization - done\n",
      "rescaling - done\n",
      "numerical data is ready\n"
     ]
    }
   ],
   "source": [
    "# imputation and outlier treatment (median, IQR)\n",
    "# nmrcl_X_test[nmrcl_X_train_columns].shape\n",
    "\n",
    "nmrcl_X_test = nmrcl_X_test[nmrcl_X_train_columns]\n",
    "\n",
    "nmrcl_X_test = nmrcl_X_test.fillna(nmrcl_X_train.median())\n",
    "\n",
    "nmrcl_X_test = outlier_replacer(nmrcl_X_test)\n",
    "\n",
    "nmrcl_X_test_columns = nmrcl_X_test.columns\n",
    "\n",
    "\n",
    "print('imputation and outlier treatment - done')\n",
    "\n",
    "# This is a sub-optimal, temporary measure, as I haven't figured out \n",
    "# how to do supervised discretization.\n",
    "## fit_transform fot training and transform for testing\n",
    "#discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='kmeans')\n",
    "discretized_nmrcl_X_test = discretizer.transform(nmrcl_X_test)\n",
    "\n",
    "print('discretization - done')\n",
    "\n",
    "# Min_max\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "rescaled_discretized_X_test = scaler.transform(np.array(discretized_nmrcl_X_test))\n",
    "\n",
    "print('rescaling - done')\n",
    "print('numerical data is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328835, 46)\n"
     ]
    }
   ],
   "source": [
    "print(rescaled_discretized_X_test.shape)\n",
    "print(rescaled_discretized_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding and stacking all the frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding for categorical variables\n",
    "\n",
    "# using feature-engine open-source librabry\n",
    "# https://feature-engine.readthedocs.io/en/latest/index.html \n",
    "\n",
    "ohe_enc = OneHotCategoricalEncoder(\n",
    "    top_categories=None,\n",
    "    drop_last=True)\n",
    "\n",
    "ohe_enc.fit(ctgrcl_X_train)\n",
    "\n",
    "ctgrcl_X_train = ohe_enc.transform(ctgrcl_X_train)\n",
    "ctgrcl_X_test = ohe_enc.transform(ctgrcl_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 98)\n",
      "(328835, 98)\n"
     ]
    }
   ],
   "source": [
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After rescaling a 2D numpy is returned, the following procedure\n",
    "# turns it into a pandas df and stacks it together with the\n",
    "# categorical dummies.\n",
    "\n",
    "rescaled_discretized_X_train = pd.DataFrame(rescaled_discretized_X_train)\n",
    "rescaled_discretized_X_test = pd.DataFrame(rescaled_discretized_X_test) \n",
    "\n",
    "rescaled_discretized_X_train.index = ctgrcl_X_train.index\n",
    "rescaled_discretized_X_test.index = ctgrcl_X_test.index\n",
    "\n",
    "rescaled_discretized_X_train.columns = nmrcl_X_train_columns\n",
    "rescaled_discretized_X_test.columns = nmrcl_X_test_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([rescaled_discretized_X_train,ctgrcl_X_train],axis=1)\n",
    "final_X_test = pd.concat([rescaled_discretized_X_test,ctgrcl_X_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([final_X_train,y_train],axis=1)\n",
    "final_X_test = pd.concat([final_X_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train.to_csv('Data/loan_club_train.csv')\n",
    "final_X_test.to_csv('Data/loan_club_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 145)\n",
      "(328835, 145)\n"
     ]
    }
   ],
   "source": [
    "print(final_X_train.shape)\n",
    "print(final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
