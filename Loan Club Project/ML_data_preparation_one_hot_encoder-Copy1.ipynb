{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dtale\n",
    "#from caimcaim import CAIMD # https://github.com/airysen/caimcaim \n",
    "# not working for me.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder\n",
    "\n",
    "\n",
    "# Display options\n",
    "\n",
    "%matplotlib\n",
    "%matplotlib inline\n",
    "#pd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\n",
    "pd.options.display.float_format = '{:.4f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00\n",
    "pd.set_option('display.max_columns', 100) #  display all the columns\n",
    "pd.set_option('display.max_rows', 100) # display all the rows\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"350\"\n",
       "            src=\"http://Macbook-Shmackbook.local:40000/dtale/iframe/2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a1faa0490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtale.show(df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to be used later in the code.\n",
    "\n",
    "\n",
    "def less_than_1pct_cat_replace(df,pct=0.01):\n",
    "    \"\"\"\n",
    "    Replace all the categorical values who's proportion\n",
    "    is less than pct with 'other'. \n",
    "    !!! Returns two objects.\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        \n",
    "        selection = df[column].value_counts(normalize=True)<pct\n",
    "        \n",
    "        list_to_replace = selection[selection==True].index\n",
    "        \n",
    "        dictionary[column] = list(list_to_replace.values)\n",
    "        \n",
    "        mask = df[column].isin(list_to_replace)\n",
    "        \n",
    "        df[column][mask] = 'other'\n",
    "    \n",
    "    return dictionary, df\n",
    "\n",
    "\n",
    "\n",
    "def outlier_replacer(df):\n",
    "    \"\"\"\n",
    "    Replace all the outliers in a numerical df using \n",
    "    IQR methodology.\n",
    "    \n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        quartile_1, quartile_3 = np.percentile(df[column], [25, 75])\n",
    "        iqr = quartile_3 - quartile_1\n",
    "        lower_bound = quartile_1 - (float(iqr) * 1.5)\n",
    "        upper_bound = quartile_3 + (float(iqr) * 1.5)\n",
    "        df.loc[(df[column]<lower_bound) | (df[column] > upper_bound),[column]] = df[column].median()\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_single_unique_values(dataframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Drop all the columns that only contain one unique value.\n",
    "    not optimized for categorical features yet.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cols_to_drop = dataframe.nunique()\n",
    "    cols_to_drop = cols_to_drop.loc[cols_to_drop.values==1].index\n",
    "    dataframe = dataframe.drop(cols_to_drop,axis=1)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                  int64\n",
       "funded_amnt                int64\n",
       "funded_amnt_inv          float64\n",
       "term                      object\n",
       "int_rate                 float64\n",
       "                          ...   \n",
       "settlement_status        float64\n",
       "settlement_date          float64\n",
       "settlement_amount        float64\n",
       "settlement_percentage    float64\n",
       "settlement_term          float64\n",
       "Length: 139, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning:\n",
      "\n",
      "Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is loaded\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "df = pd.read_csv('Data/loan.csv')\n",
    "print('df is loaded')\n",
    "df.drop(['issue_d','earliest_cr_line','last_pymnt_d',\n",
    "        'last_credit_pull_d','id','member_id','settlement_date'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any observation with the loan status 'current' has no value for the analysis as there is no way of knowing for sure the outcome of a loan. Similarlry other cases of status such as 'Does not meet the credit policy. Status:Fully Paid', 'Does not meet the credit policy. Status:Charged Off', 'Default' have been classified accordingly to their outocme, to reduce data sparcity. So those observations are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             1041952\n",
       "Current                                                 919695\n",
       "Charged Off                                             261655\n",
       "Late (31-120 days)                                       21897\n",
       "In Grace Period                                           8952\n",
       "Late (16-30 days)                                         3737\n",
       "Does not meet the credit policy. Status:Fully Paid        1988\n",
       "Does not meet the credit policy. Status:Charged Off        761\n",
       "Default                                                     31\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data, dropping features with single uniqu values\n",
    "\n",
    "y = df[['loan_status']]\n",
    "X = df.drop('loan_status',axis='columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating categorical part of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:9114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# splitting the df into categorical and numerical parts\n",
    "ctgrcl_df = df.select_dtypes(include=['object'])\n",
    "nmrcl_df = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# have to drop the y feature\n",
    "ctgrcl_df.drop(['loan_status'],axis='columns',inplace=True)\n",
    "\n",
    "ctgrcl_df.fillna('other',inplace=True)\n",
    "\n",
    "# '<,>,+' have to be replaced for correct working of get_dummies function\n",
    "emp_lengthdict = {'10+ years':'ten years or more', \n",
    " '2 years':'two years', \n",
    " '< 1 year':'less than a year', \n",
    " '3 years':'three years', \n",
    " 'other':'other', \n",
    " '1 year':'one year',\n",
    " '5 years':'five years', \n",
    " '4 years':'four years', \n",
    " '6 years':'six years', \n",
    " '7 years':'seven years', \n",
    " '8 years':'eight years', \n",
    " '9 years':'nine years'}\n",
    "\n",
    "ctgrcl_df.emp_length.replace(emp_lengthdict,inplace=True)\n",
    "ctgrcl_df = less_than_1pct_cat_replace(ctgrcl_df,pct=0.01)\n",
    "\n",
    "# now the categorical part of the df is ready for train_test_split\n",
    "# stiching categorical and numerical data together\n",
    "df = pd.concat([nmrcl_df,ctgrcl_df,df[['loan_status']]],axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data into categorical and numerical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing training and testing data into categorical and numerical parts\n",
    "ctgrcl_X_train = X_train.select_dtypes(include=['object'])\n",
    "nmrcl_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "\n",
    "ctgrcl_X_test = X_test.select_dtypes(include=['object'])\n",
    "nmrcl_X_test = X_test.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695501, 64)\n",
      "(565167, 64)\n"
     ]
    }
   ],
   "source": [
    "print(nmrcl_X_train.shape)\n",
    "print(nmrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1695501 entries, 1404520 to 2219110\n",
      "Data columns (total 80 columns):\n",
      "loan_amnt                     int64\n",
      "funded_amnt                   int64\n",
      "funded_amnt_inv               float64\n",
      "term                          object\n",
      "int_rate                      float64\n",
      "installment                   float64\n",
      "grade                         object\n",
      "sub_grade                     object\n",
      "emp_title                     object\n",
      "emp_length                    object\n",
      "home_ownership                object\n",
      "annual_inc                    float64\n",
      "verification_status           object\n",
      "pymnt_plan                    object\n",
      "purpose                       object\n",
      "title                         object\n",
      "addr_state                    object\n",
      "dti                           float64\n",
      "delinq_2yrs                   float64\n",
      "inq_last_6mths                float64\n",
      "open_acc                      float64\n",
      "pub_rec                       float64\n",
      "revol_bal                     int64\n",
      "revol_util                    float64\n",
      "total_acc                     float64\n",
      "initial_list_status           object\n",
      "out_prncp                     float64\n",
      "out_prncp_inv                 float64\n",
      "total_pymnt                   float64\n",
      "total_pymnt_inv               float64\n",
      "total_rec_prncp               float64\n",
      "total_rec_int                 float64\n",
      "total_rec_late_fee            float64\n",
      "recoveries                    float64\n",
      "collection_recovery_fee       float64\n",
      "last_pymnt_amnt               float64\n",
      "collections_12_mths_ex_med    float64\n",
      "application_type              object\n",
      "acc_now_delinq                float64\n",
      "tot_coll_amt                  float64\n",
      "tot_cur_bal                   float64\n",
      "total_rev_hi_lim              float64\n",
      "acc_open_past_24mths          float64\n",
      "avg_cur_bal                   float64\n",
      "bc_open_to_buy                float64\n",
      "bc_util                       float64\n",
      "chargeoff_within_12_mths      float64\n",
      "delinq_amnt                   float64\n",
      "mo_sin_old_il_acct            float64\n",
      "mo_sin_old_rev_tl_op          float64\n",
      "mo_sin_rcnt_rev_tl_op         float64\n",
      "mo_sin_rcnt_tl                float64\n",
      "mort_acc                      float64\n",
      "mths_since_recent_bc          float64\n",
      "mths_since_recent_inq         float64\n",
      "num_accts_ever_120_pd         float64\n",
      "num_actv_bc_tl                float64\n",
      "num_actv_rev_tl               float64\n",
      "num_bc_sats                   float64\n",
      "num_bc_tl                     float64\n",
      "num_il_tl                     float64\n",
      "num_op_rev_tl                 float64\n",
      "num_rev_accts                 float64\n",
      "num_rev_tl_bal_gt_0           float64\n",
      "num_sats                      float64\n",
      "num_tl_120dpd_2m              float64\n",
      "num_tl_30dpd                  float64\n",
      "num_tl_90g_dpd_24m            float64\n",
      "num_tl_op_past_12m            float64\n",
      "pct_tl_nvr_dlq                float64\n",
      "percent_bc_gt_75              float64\n",
      "pub_rec_bankruptcies          float64\n",
      "tax_liens                     float64\n",
      "tot_hi_cred_lim               float64\n",
      "total_bal_ex_mort             float64\n",
      "total_bc_limit                float64\n",
      "total_il_high_credit_limit    float64\n",
      "hardship_flag                 object\n",
      "disbursement_method           object\n",
      "debt_settlement_flag          object\n",
      "dtypes: float64(61), int64(3), object(16)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "#X_train.info()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating numerical X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation and outlier treatment - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (8) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 27 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 32 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:972: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return_n_iter=True)\n",
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 39 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discretization - done\n",
      "rescaling - done\n",
      "numerical data is ready\n"
     ]
    }
   ],
   "source": [
    "# imputation and outlier treatment (median, IQR)\n",
    "nmrcl_X_train = nmrcl_X_train.fillna(nmrcl_X_train.median())\n",
    "\n",
    "nmrcl_X_train = outlier_replacer(nmrcl_X_train)\n",
    "nmrcl_X_train = remove_single_unique_values(nmrcl_X_train)\n",
    "nmrcl_X_train_columns = nmrcl_X_train.columns\n",
    "X_train_median_values = nmrcl_X_train.median()\n",
    "\n",
    "print('imputation and outlier treatment - done')\n",
    "\n",
    "# This is a sub-optimal, temporary measure, as I haven't figured out \n",
    "# how to do supervised discretization.\n",
    "discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='kmeans')\n",
    "discretized_X_train = discretizer.fit_transform(nmrcl_X_train)\n",
    "\n",
    "print('discretization - done')\n",
    "\n",
    "# Min_max\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "rescaled_discretized_X_train = scaler.fit_transform(np.array(discretized_X_train))\n",
    "\n",
    "print('rescaling - done')\n",
    "print('numerical data is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating numerical X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation and outlier treatment - done\n",
      "discretization - done\n",
      "rescaling - done\n",
      "numerical data is ready\n"
     ]
    }
   ],
   "source": [
    "# imputation and outlier treatment (median, IQR)\n",
    "# nmrcl_X_test[nmrcl_X_train_columns].shape\n",
    "\n",
    "nmrcl_X_test = nmrcl_X_test[nmrcl_X_train_columns]\n",
    "\n",
    "nmrcl_X_test = nmrcl_X_test.fillna(nmrcl_X_train.median())\n",
    "\n",
    "nmrcl_X_test = outlier_replacer(nmrcl_X_test)\n",
    "\n",
    "nmrcl_X_test_columns = nmrcl_X_test.columns\n",
    "\n",
    "\n",
    "print('imputation and outlier treatment - done')\n",
    "\n",
    "# This is a sub-optimal, temporary measure, as I haven't figured out \n",
    "# how to do supervised discretization.\n",
    "## fit_transform fot training and transform for testing\n",
    "#discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='kmeans')\n",
    "discretized_nmrcl_X_test = discretizer.transform(nmrcl_X_test)\n",
    "\n",
    "print('discretization - done')\n",
    "\n",
    "# Min_max\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "rescaled_discretized_X_test = scaler.transform(np.array(discretized_nmrcl_X_test))\n",
    "\n",
    "print('rescaling - done')\n",
    "print('numerical data is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328835, 46)\n"
     ]
    }
   ],
   "source": [
    "print(rescaled_discretized_X_test.shape)\n",
    "print(rescaled_discretized_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding and stacking all the frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding for categorical variables\n",
    "\n",
    "# using feature-engine open-source librabry\n",
    "# https://feature-engine.readthedocs.io/en/latest/index.html \n",
    "\n",
    "ohe_enc = OneHotCategoricalEncoder(\n",
    "    top_categories=None,\n",
    "    drop_last=True)\n",
    "\n",
    "ohe_enc.fit(ctgrcl_X_train)\n",
    "\n",
    "ctgrcl_X_train = ohe_enc.transform(ctgrcl_X_train)\n",
    "ctgrcl_X_test = ohe_enc.transform(ctgrcl_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 98)\n",
      "(328835, 98)\n"
     ]
    }
   ],
   "source": [
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After rescaling a 2D numpy is returned, the following procedure\n",
    "# turns it into a pandas df and stacks it together with the\n",
    "# categorical dummies.\n",
    "\n",
    "rescaled_discretized_X_train = pd.DataFrame(rescaled_discretized_X_train)\n",
    "rescaled_discretized_X_test = pd.DataFrame(rescaled_discretized_X_test) \n",
    "\n",
    "rescaled_discretized_X_train.index = ctgrcl_X_train.index\n",
    "rescaled_discretized_X_test.index = ctgrcl_X_test.index\n",
    "\n",
    "rescaled_discretized_X_train.columns = nmrcl_X_train_columns\n",
    "rescaled_discretized_X_test.columns = nmrcl_X_test_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([rescaled_discretized_X_train,ctgrcl_X_train],axis=1)\n",
    "final_X_test = pd.concat([rescaled_discretized_X_test,ctgrcl_X_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([final_X_train,y_train],axis=1)\n",
    "final_X_test = pd.concat([final_X_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train.to_csv('Data/loan_club_train.csv')\n",
    "final_X_test.to_csv('Data/loan_club_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 145)\n",
      "(328835, 145)\n"
     ]
    }
   ],
   "source": [
    "print(final_X_train.shape)\n",
    "print(final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
