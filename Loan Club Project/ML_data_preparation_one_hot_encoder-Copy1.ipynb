{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-29 11:51:58,998 - ERROR    - Exception in callback functools.partial(<function Kernel.enter_eventloop.<locals>.advance_eventloop at 0x1a6a2ddf80>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 310, in advance_eventloop\n",
      "    eventloop(self)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dtale\n",
    "#from caimcaim import CAIMD # https://github.com/airysen/caimcaim \n",
    "# not working for me.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder\n",
    "\n",
    "# Display options\n",
    "\n",
    "%matplotlib\n",
    "%matplotlib inline\n",
    "#pd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\n",
    "pd.options.display.float_format = '{:.4f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00\n",
    "pd.set_option('display.max_columns', 100) #  display all the columns\n",
    "pd.set_option('display.max_rows', 100) # display all the rows\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to be used later in the code.\n",
    "\n",
    "\n",
    "def less_than_1pct_cat_replace(df,pct=0.01):\n",
    "    \"\"\"\n",
    "    Replace all the categorical values who's proportion\n",
    "    is less than pct with 'other'. \n",
    "    !!! Returns two objects.\n",
    "    \"\"\"\n",
    "    list_of_stuff_to_replace = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        selection = df[column].value_counts(normalize=True)<pct\n",
    "        list_to_replace = selection[selection==True].index\n",
    "        \n",
    "        for item in list_to_replace:\n",
    "            list_of_stuff_to_replace.append(item)\n",
    "        \n",
    "        mask = df[column].isin(list_to_replace)\n",
    "        df[column][mask] = 'other'\n",
    "    \n",
    "    return  df,list_of_stuff_to_replace\n",
    "\n",
    "\n",
    "\n",
    "def outlier_replacer(df,test_df):    \n",
    "    \"\"\"\n",
    "    Replace all the outliers in a numerical df using \n",
    "    IQR methodology. \n",
    "    \n",
    "    \"\"\"\n",
    "    # preparing the training data    \n",
    "    df = remove_single_unique_values(df)\n",
    "    df = df.fillna(df.median())\n",
    "    df = remove_single_unique_values(df)\n",
    "    nmrcl_X_train_columns = df.columns\n",
    "    \n",
    "    # preparing testing data\n",
    "    test_df = test_df[nmrcl_X_train_columns]\n",
    "    test_df = test_df.fillna(df.median())\n",
    "    \n",
    "    upper_bound_dict = {}\n",
    "    lower_bound_dict = {}\n",
    "    \n",
    "    # looping over every column\n",
    "    for column in df.columns:\n",
    "        quartile_1, quartile_3 = np.percentile(df[column], [25, 75])\n",
    "        iqr = quartile_3 - quartile_1\n",
    "        lower_bound = quartile_1 - (float(iqr) * 1.5)\n",
    "        upper_bound = quartile_3 + (float(iqr) * 1.5)\n",
    "        \n",
    "        # populating dictionary with boundary values\n",
    "        upper_bound_dict[column] = upper_bound\n",
    "        lower_bound_dict[column] = lower_bound\n",
    "        \n",
    "        upper_bound_df = pd.DataFrame(upper_bound_dict,index=np.arange(0,1)).T\n",
    "        lower_bound_df = pd.DataFrame(lower_bound_dict,index=np.arange(0,1)).T\n",
    "        \n",
    "        df.loc[(df[column]<lower_bound) | (df[column] > upper_bound),[column]] = df[column].median()\n",
    "        test_df.loc[(test_df[column]<lower_bound) | (test_df[column] > upper_bound),[column]] = df[column].median()\n",
    "        \n",
    "    iqr_bounds = pd.merge(upper_bound_df, lower_bound_df, left_index=True, right_index=True)    \n",
    "    iqr_bounds.columns = ['upper bound','lower bound']\n",
    "    iqr_bounds['medians'] = df.median()    \n",
    "    \n",
    "    df = remove_single_unique_values(df)\n",
    "    test_df = remove_single_unique_values(test_df)\n",
    " \n",
    "    return  df,test_df,iqr_bounds\n",
    "\n",
    "\n",
    "def remove_single_unique_values(dataframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Drop all the columns that only contain one unique value.\n",
    "    not optimized for categorical features yet.\n",
    "    \n",
    "    \"\"\"    \n",
    "    cols_to_drop = dataframe.nunique()\n",
    "    cols_to_drop = cols_to_drop.loc[cols_to_drop.values==1].index\n",
    "    dataframe = dataframe.drop(cols_to_drop,axis=1)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is loaded\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "df = pd.read_csv('Data/loan.csv')\n",
    "print('df is loaded')\n",
    "df.drop(['issue_d','earliest_cr_line','last_pymnt_d',\n",
    "        'last_credit_pull_d','id','member_id','settlement_date',\n",
    "        'next_pymnt_d','zip_code'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260668, 138)\n"
     ]
    }
   ],
   "source": [
    "df = df.infer_objects()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260668, 100)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=1,how='any',thresh=int(0.3*len(df)),inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data, dropping features with single uniqu values\n",
    "\n",
    "y = df[['loan_status']]\n",
    "X = df.drop('loan_status',axis='columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                            random_state=42, stratify=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data into categorical and numerical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing training and testing data into categorical and numerical parts\n",
    "ctgrcl_X_train = X_train.select_dtypes(include=['object'])\n",
    "nmrcl_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "\n",
    "ctgrcl_X_test = X_test.select_dtypes(include=['object'])\n",
    "nmrcl_X_test = X_test.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695501, 81)\n",
      "(565167, 81)\n",
      "********\n",
      "(1695501, 18)\n",
      "(565167, 18)\n"
     ]
    }
   ],
   "source": [
    "print(nmrcl_X_train.shape)\n",
    "print(nmrcl_X_test.shape)\n",
    "print('********')\n",
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Treatment (both training and testing data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmrcl_X_train,nmrcl_X_test,boundaries = outlier_replacer(nmrcl_X_train,nmrcl_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving columns and indexes before discretization and rescaling\n",
    "\n",
    "num_train_cols = nmrcl_X_train.columns\n",
    "num_train_index = nmrcl_X_train.index\n",
    "\n",
    "num_train_cols = nmrcl_X_test.columns\n",
    "num_train_index = nmrcl_X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretizing and rescaling (both train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='kmeans')\n",
    "discretized_X_train = discretizer.fit_transform(nmrcl_X_train)\n",
    "\n",
    "print('train discretization - done')\n",
    "\n",
    "# Min_max\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "rescaled_discretized_X_train = scaler.fit_transform(np.array(discretized_X_train))\n",
    "print('train rescaling - done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discretization - done\n"
     ]
    }
   ],
   "source": [
    "discretized_nmrcl_X_test = discretizer.transform(nmrcl_X_test)\n",
    "rescaled_discretized_X_test = scaler.transform(np.array(discretized_nmrcl_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695501, 60)\n",
      "(565167, 60)\n"
     ]
    }
   ],
   "source": [
    "print(rescaled_discretized_X_train.shape)\n",
    "print(rescaled_discretized_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgrcl_X_train.drop(['next_pymnt_d','zip_code'],axis=1,inplace=True)\n",
    "ctgrcl_X_test.drop(['next_pymnt_d','zip_code'],axis=1,inplace=True)\n",
    "\n",
    "ctgrcl_X_train.fillna('other',inplace=True)\n",
    "ctgrcl_X_test.fillna('other',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!\n",
    "Because emp_title and title features are waaaaaay tooooo sparce for the general logic of \n",
    "\"less than 1% replacer\" I have decided to use a simple list to replacement logic.\n",
    "It's not generalizable but this is the optimal strategy in this case.\n",
    "\n",
    "* even when I use the dictionary or a list (from train df) to replace the test df with \"other\", there are still titles that are not overlaping, that's how sparce titles are. Sure I could use some set logic but seems like an overkill in this P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_title_to_keep = ['Teacher','Manager','Owner']\n",
    "title_to_keep = ['Debt consolidation','Credit card refinancing','Home improvement','Major purchase',            \n",
    "'Medical expenses','Business' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emp_title(title):\n",
    "    if title in emp_title_to_keep:\n",
    "        return title\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "    \n",
    "def title(title):\n",
    "    if title in title_to_keep:\n",
    "        return title\n",
    "    else:\n",
    "        return 'other'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgrcl_X_train['emp_title'] = ctgrcl_X_train['emp_title'].apply(emp_title)\n",
    "ctgrcl_X_train['title'] = ctgrcl_X_train['title'].apply(title)\n",
    "ctgrcl_X_test['emp_title'] = ctgrcl_X_test['emp_title'].apply(emp_title)\n",
    "ctgrcl_X_test['title'] = ctgrcl_X_test['title'].apply(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "def less_than_1pct_cat_replace(df,test_df,pct=0.01):\n",
    "    \"\"\"\n",
    "    Replace all the categorical values who's proportion\n",
    "    is less than pct with 'other'. \n",
    "    !!! Returns two objects.\n",
    "    \"\"\"\n",
    "\n",
    "    for column in df.columns:\n",
    "        selection = df[column].value_counts(normalize=True)<pct\n",
    "        list_to_replace = selection[selection==True].index\n",
    "        mask = df[column].isin(list_to_replace)\n",
    "        df[column][mask] = 'other'\n",
    "        mask = test_df[column].isin(list_to_replace)\n",
    "        test_df[column][mask] = 'other'\n",
    "    \n",
    "    return  df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding and stacking all the frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding for categorical variables\n",
    "\n",
    "# using feature-engine open-source librabry\n",
    "# https://feature-engine.readthedocs.io/en/latest/index.html \n",
    "\n",
    "ohe_enc = OneHotCategoricalEncoder(\n",
    "    top_categories=None,\n",
    "    drop_last=True)\n",
    "\n",
    "ohe_enc.fit(ctgrcl_X_train)\n",
    "\n",
    "ctgrcl_X_train = ohe_enc.transform(ctgrcl_X_train)\n",
    "ctgrcl_X_test = ohe_enc.transform(ctgrcl_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 98)\n",
      "(328835, 98)\n"
     ]
    }
   ],
   "source": [
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After rescaling a 2D numpy is returned, the following procedure\n",
    "# turns it into a pandas df and stacks it together with the\n",
    "# categorical dummies.\n",
    "\n",
    "rescaled_discretized_X_train = pd.DataFrame(rescaled_discretized_X_train)\n",
    "rescaled_discretized_X_test = pd.DataFrame(rescaled_discretized_X_test) \n",
    "\n",
    "rescaled_discretized_X_train.index = ctgrcl_X_train.index\n",
    "rescaled_discretized_X_test.index = ctgrcl_X_test.index\n",
    "\n",
    "rescaled_discretized_X_train.columns = nmrcl_X_train_columns\n",
    "rescaled_discretized_X_test.columns = nmrcl_X_test_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([rescaled_discretized_X_train,ctgrcl_X_train],axis=1)\n",
    "final_X_test = pd.concat([rescaled_discretized_X_test,ctgrcl_X_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([final_X_train,y_train],axis=1)\n",
    "final_X_test = pd.concat([final_X_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train.to_csv('Data/loan_club_train.csv')\n",
    "final_X_test.to_csv('Data/loan_club_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(986504, 145)\n",
      "(328835, 145)\n"
     ]
    }
   ],
   "source": [
    "print(final_X_train.shape)\n",
    "print(final_X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
