{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dtale\n",
    "#from caimcaim import CAIMD\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder\n",
    "from feature_engine import outlier_removers as outr\n",
    "from feature_engine import categorical_encoders as ce\n",
    "\n",
    "# Display options\n",
    "\n",
    "%matplotlib\n",
    "%matplotlib inline\n",
    "#pd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\n",
    "pd.options.display.float_format = '{:.4f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00\n",
    "pd.set_option('display.max_columns', 100) #  display all the columns\n",
    "#pd.set_option('display.max_rows', 100) # display all the rows\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})\n",
    "\n",
    "\n",
    "def remove_single_unique_values(dataframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Drop all the columns that only contain one unique value.\n",
    "    not optimized for categorical features yet.\n",
    "    \n",
    "    \"\"\"    \n",
    "    cols_to_drop = dataframe.nunique()\n",
    "    cols_to_drop = cols_to_drop.loc[cols_to_drop.values==1].index\n",
    "    dataframe = dataframe.drop(cols_to_drop,axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babyhandzzz/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is loaded\n",
      "(2260668, 98)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/loan.csv')\n",
    "print('df is loaded')\n",
    "df.drop(['issue_d','earliest_cr_line','last_pymnt_d',\n",
    "        'last_credit_pull_d','id','member_id','settlement_date',\n",
    "        'next_pymnt_d','zip_code'],axis='columns',inplace=True)\n",
    "\n",
    "df = df.infer_objects()\n",
    "df.dropna(axis=1,how='any',thresh=int(0.3*len(df)),inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fully Paid</th>\n",
       "      <td>46.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current</th>\n",
       "      <td>40.6824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charged Off</th>\n",
       "      <td>11.5742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Late (31-120 days)</th>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Grace Period</th>\n",
       "      <td>0.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Late (16-30 days)</th>\n",
       "      <td>0.1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does not meet the credit policy. Status:Fully Paid</th>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does not meet the credit policy. Status:Charged Off</th>\n",
       "      <td>0.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    loan_status\n",
       "Fully Paid                                              46.0904\n",
       "Current                                                 40.6824\n",
       "Charged Off                                             11.5742\n",
       "Late (31-120 days)                                       0.9686\n",
       "In Grace Period                                          0.3960\n",
       "Late (16-30 days)                                        0.1653\n",
       "Does not meet the credit policy. Status:Fully Paid       0.0879\n",
       "Does not meet the credit policy. Status:Charged...       0.0337\n",
       "Default                                                  0.0014"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df['loan_status'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label-specific manipulations\n",
    "\n",
    "Some of the labels have no ML value as they do no provide any terminal status of a loan.\n",
    "\n",
    "* 46.09% of the loans are lebeled 'Current'.\n",
    "* 1.17% of the loans are lebeled 'Late'.\n",
    "* 0.4% of the loans are lebeled 'IN Grace Period'.\n",
    "\n",
    "There is no way to know what the actual outcome of those loans is going to be.\n",
    "They will are dropped.\n",
    "\n",
    "* 'Does not meet the credit policy. Status:Fully Paid' \n",
    "* 'Does not meet the credit policy. Status:Charged Off'\n",
    "\n",
    "These labels differ from 'Fully Paid' or 'Charged Off' however they can also be classified as their status suggest into : 'Fully Paid' and 'Charged Off'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid     1043940\n",
       "Charged Off     262416\n",
       "Default             31\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df.loan_status!='Current']\n",
    "df = df.loc[df.loan_status!='Late (31-120 days)']\n",
    "df = df.loc[df.loan_status!='Late (16-30 days)']\n",
    "df = df.loc[df.loan_status!='In Grace Period']\n",
    "\n",
    "dictionary = {'Does not meet the credit policy. Status:Fully Paid':'Fully Paid',\n",
    "             'Does not meet the credit policy. Status:Charged Off':'Charged Off'}\n",
    "\n",
    "df['loan_status'].replace(dictionary,inplace=True)\n",
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['loan_status']]\n",
    "X = df.drop('loan_status',axis='columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                            random_state=42, stratify=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data into categorical and numerical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical part:\n",
      "(979790, 81)\n",
      "(326597, 81)\n",
      "Categorical part:\n",
      "(979790, 16)\n",
      "(326597, 16)\n"
     ]
    }
   ],
   "source": [
    "# dividing training and testing data into categorical and numerical parts\n",
    "ctgrcl_X_train = X_train.select_dtypes(include=['object'])\n",
    "nmrcl_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "\n",
    "ctgrcl_X_test = X_test.select_dtypes(include=['object'])\n",
    "nmrcl_X_test = X_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "print('Numerical part:')\n",
    "print(nmrcl_X_train.shape)\n",
    "print(nmrcl_X_test.shape)\n",
    "print('Categorical part:')\n",
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial cleaning (numerical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979790, 80)\n"
     ]
    }
   ],
   "source": [
    "# cleaning\n",
    "nmrcl_X_train = nmrcl_X_train.fillna(nmrcl_X_train.median())\n",
    "\n",
    "\"\"\" \n",
    "Training df medians have to be saved as a pd.Series object othervise replace() \n",
    "method does not work when replacing NaN in testing df.\n",
    "\"\"\"\n",
    "\n",
    "nmrcl_X_train_medians = pd.Series(nmrcl_X_train.median())\n",
    "nmrcl_X_train = remove_single_unique_values(nmrcl_X_train)\n",
    "print(nmrcl_X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979790, 80)\n",
      "(326597, 80)\n"
     ]
    }
   ],
   "source": [
    "# outlier treatment\n",
    "capper = outr.Winsorizer(distribution='skewed', tail='both', fold=1.5)\n",
    "capper.fit(nmrcl_X_train)\n",
    "nmrcl_X_train_columns = nmrcl_X_train.columns\n",
    "nmrcl_X_train = capper.transform(nmrcl_X_train)\n",
    "\n",
    "nmrcl_X_test = nmrcl_X_test[nmrcl_X_train_columns]\n",
    "nmrcl_X_test.fillna(nmrcl_X_train_medians,inplace=True)\n",
    "nmrcl_X_test = capper.transform(nmrcl_X_test)\n",
    "\n",
    "print(nmrcl_X_train.shape)\n",
    "print(nmrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving indeces and column names of the dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving columns and indexes before discretization and rescaling\n",
    "num_train_cols = nmrcl_X_train.columns\n",
    "num_train_index = nmrcl_X_train.index\n",
    "\n",
    "num_test_cols = nmrcl_X_test.columns\n",
    "num_test_index = nmrcl_X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization using Kbins method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = KBinsDiscretizer(n_bins=12, encode='ordinal', strategy='kmeans')\n",
    "discretizer.fit(nmrcl_X_train)\n",
    "nmrcl_X_train_discr = discretizer.transform(nmrcl_X_train)\n",
    "nmrcl_X_test_discr = discretizer.transform(nmrcl_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(979790, 80)\n",
      "(326597, 80)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(nmrcl_X_train_discr)\n",
    "nmrcl_X_train_discr_rscld = scaler.transform(nmrcl_X_train_discr)\n",
    "nmrcl_X_test_discr_rscld = scaler.transform(nmrcl_X_test_discr)\n",
    "\n",
    "# a quick check to make sure df shapes are the same.\n",
    "print(nmrcl_X_test_discr_rscld.shape == nmrcl_X_train_discr_rscld.shape)\n",
    "print(nmrcl_X_train_discr_rscld.shape)\n",
    "print(nmrcl_X_test_discr_rscld.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                     True\n",
       "grade                    True\n",
       "sub_grade                True\n",
       "emp_title                True\n",
       "emp_length               True\n",
       "home_ownership           True\n",
       "verification_status      True\n",
       "pymnt_plan               True\n",
       "purpose                  True\n",
       "title                    True\n",
       "addr_state               True\n",
       "initial_list_status      True\n",
       "application_type         True\n",
       "hardship_flag           False\n",
       "disbursement_method      True\n",
       "debt_settlement_flag     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctgrcl_X_train.fillna('other',inplace=True)\n",
    "ctgrcl_X_test.fillna('other',inplace=True)\n",
    "\n",
    "encoder = ce.RareLabelCategoricalEncoder(tol=0.01)\n",
    "encoder.fit(ctgrcl_X_train)\n",
    "\n",
    "\"\"\"\n",
    "The default behaviour of the function is such that it replaces infrequent categories with\n",
    "the word \"Rare\" which would be fine if the dataframe didn't have category 'other',\n",
    "that's why 'replace' method is used\n",
    "\"\"\"\n",
    "\n",
    "ctgrcl_X_train = encoder.transform(ctgrcl_X_train)\n",
    "ctgrcl_X_train.replace('Rare','other',inplace=True)\n",
    "ctgrcl_X_test = encoder.transform(ctgrcl_X_test)\n",
    "ctgrcl_X_test.replace('Rare','other',inplace=True)\n",
    "\n",
    "# quick check to make sure that the categories are the same.\n",
    "ctgrcl_X_test.nunique() == ctgrcl_X_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979790, 98)\n",
      "(326597, 98)\n"
     ]
    }
   ],
   "source": [
    "# OneHotEncoding for categorical variables\n",
    "ohe_enc = OneHotCategoricalEncoder(top_categories=None,drop_last=True)\n",
    "\n",
    "ohe_enc.fit(ctgrcl_X_train)\n",
    "\n",
    "ctgrcl_X_train = ohe_enc.transform(ctgrcl_X_train)\n",
    "ctgrcl_X_test = ohe_enc.transform(ctgrcl_X_test)\n",
    "\n",
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking all the dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979790, 179)\n",
      "(326597, 179)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "After rescaling numerical data 2D numpy arrays are returned, the following procedure\n",
    "turns them into pandas dfs and stacks them with categorical dummies and corresponding \n",
    "labels. \n",
    "\"\"\"\n",
    "\n",
    "nmrcl_X_train_discr_rescl = pd.DataFrame(nmrcl_X_train_discr_rscld)\n",
    "nmrcl_X_test_discr_rescl= pd.DataFrame(nmrcl_X_test_discr_rscld) \n",
    "\n",
    "nmrcl_X_train_discr_rescl.index = ctgrcl_X_train.index\n",
    "nmrcl_X_test_discr_rescl.index = ctgrcl_X_test.index\n",
    "\n",
    "nmrcl_X_train_discr_rescl.columns = nmrcl_X_train_columns\n",
    "nmrcl_X_test_discr_rescl.columns = nmrcl_X_train_columns\n",
    "\n",
    "final_train = pd.concat([nmrcl_X_train_discr_rescl,ctgrcl_X_train,y_train],axis=1)\n",
    "final_test = pd.concat([nmrcl_X_test_discr_rescl,ctgrcl_X_test,y_test],axis=1)\n",
    "\n",
    "print(final_train.shape)\n",
    "print(final_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_csv('Data/K_bins_train.csv')\n",
    "final_test.to_csv('Data/K_bins_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
