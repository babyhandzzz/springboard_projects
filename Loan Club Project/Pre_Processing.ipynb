{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, KBinsDiscretizer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from feature_engine import outlier_removers \n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder, RareLabelCategoricalEncoder\n",
    "import dtale\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Display options\n",
    "\n",
    "pd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\n",
    "pd.options.display.float_format = '{:.4f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00\n",
    "pd.set_option('display.max_columns', 100) #  display all the columns\n",
    "pd.set_option('display.max_rows', 100) # display all the rows\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the file that contains the fetures and info. abou the features:\n",
    "# desctption, categorical/numerical, to use or not to use.\n",
    "dictionary = pd.read_csv('Data/LCDataDictionary.csv',names=['action','feature','description'])\n",
    "dictionary['feature'].replace('total_rev_hi_lim \\xa0','total_rev_hi_lim',inplace=True)\n",
    "cols_to_use= list(dictionary['feature'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2260668, 76)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/loan.csv',low_memory=False)\n",
    "print('df is loaded')\n",
    "df = df[cols_to_use]\n",
    "df.dropna(axis=1,how='any',thresh=int(0.35*len(df)),inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Manipulations\n",
    "* Specific to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid    0.7991\n",
       "Charged Off   0.2009\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_drop = ['Current','Late (31-120 days)','Late (16-30 days)','In Grace Period','Default']\n",
    "df = df[~df.loan_status.isin(labels_to_drop)]\n",
    "\n",
    "dictionary = {'Does not meet the credit policy. Status:Fully Paid':'Fully Paid',\n",
    "             'Does not meet the credit policy. Status:Charged Off':'Charged Off'}\n",
    "\n",
    "df['loan_status'].replace(dictionary,inplace=True)\n",
    "df['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'policy_code' is dropped\n",
      "'pymnt_plan' is dropped\n",
      "(1306356, 74)\n"
     ]
    }
   ],
   "source": [
    "# As the result of this this function the following features are dropped:\n",
    "# pymnt_plan\n",
    "# policy_code\n",
    "\n",
    "# delete all the columns that contain single unique values\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        print(\"'{}' is dropped\".format(col))\n",
    "        df.drop(col,inplace=True,axis=1)\n",
    "print(df.shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = df.drop('loan_status',axis='columns').columns\n",
    "X = df[columns_to_use]\n",
    "y = df['loan_status'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                            random_state=42, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = X_train.columns[:59]\n",
    "categorical_columns = X_train.columns[59:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data into categorical and numerical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical part:\n",
      "(979767, 59)\n",
      "(326589, 59)\n",
      "Categorical part:\n",
      "(979767, 14)\n",
      "(326589, 14)\n"
     ]
    }
   ],
   "source": [
    "# dividing training and testing data into categorical and numerical parts\n",
    "nmrcl_X_train = X_train[numerical_columns]\n",
    "nmrcl_X_test = X_test[numerical_columns]\n",
    "\n",
    "ctgrcl_X_train = X_train[categorical_columns]\n",
    "ctgrcl_X_test = X_test[categorical_columns]\n",
    "\n",
    "print('Numerical part:')\n",
    "print(nmrcl_X_train.shape)\n",
    "print(nmrcl_X_test.shape)\n",
    "print('Categorical part:')\n",
    "print(ctgrcl_X_train.shape)\n",
    "print(ctgrcl_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating numerical data\n",
    "* starting with pd.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Training df medians have to be saved as a pd.Series object othervise replace() \n",
    "method does not work when replacing NaN in testing df.\n",
    "\"\"\"\n",
    "\n",
    "training_medians = pd.Series(nmrcl_X_train.median()) # get the training medians \n",
    "\n",
    "nmrcl_X_train = nmrcl_X_train.fillna(training_medians) # fillna first\n",
    "nmrcl_X_test = nmrcl_X_test.fillna(training_medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining numerical features treatment\n",
    "* I actually don't know if it's a good idea, but if we pipeline, we decrease the number of points of failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-step pipeline\n",
    "# 1.outlier replacement\n",
    "# 3.scaling removed for now\n",
    "\n",
    "# defining the sklearn-native pre-processors\n",
    "capper = outlier_removers.Winsorizer(distribution='skewed', tail='both', fold=1.5)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# piepline\n",
    "numerical_pipeline = Pipeline([('capper',capper),('scaler',scaler)])\n",
    "# apply pipeline\n",
    "nmrcl_X_train = numerical_pipeline.fit_transform(nmrcl_X_train)\n",
    "nmrcl_X_test = numerical_pipeline.transform(nmrcl_X_test)\n",
    "\n",
    "\n",
    "# get the features names\n",
    "nmrc_feature_cols = numerical_pipeline.named_steps['capper'].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast produced np.arrays back to pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline output is a numpy array, cast it back to pandas df\n",
    "nmrcl_X_train = pd.DataFrame(nmrcl_X_train, columns=nmrc_feature_cols)\n",
    "nmrcl_X_test = pd.DataFrame(nmrcl_X_test, columns=nmrc_feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining categorical features treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgrcl_X_train.fillna('other',inplace=True)\n",
    "ctgrcl_X_test.fillna('other',inplace=True)\n",
    "\n",
    "# two step pipeline:\n",
    "# 1. rare labels (frequency below 1% are changed to 'rare')\n",
    "# 2. n-1 OneHot encoding\n",
    "\n",
    "encoder = RareLabelCategoricalEncoder(tol=0.01)\n",
    "ohe_enc = OneHotCategoricalEncoder(top_categories=None,drop_last=True)\n",
    "\n",
    "categorical_pipeline = Pipeline([('rare_label',encoder),('onehot',ohe_enc)])\n",
    "\n",
    "ctgrcl_X_train = categorical_pipeline.fit_transform(ctgrcl_X_train)\n",
    "ctgrcl_X_test = categorical_pipeline.transform(ctgrcl_X_test)\n",
    "\n",
    "# reseting the index so all the dfs are alinable\n",
    "ctgrcl_X_train.reset_index(drop=True,inplace=True)\n",
    "ctgrcl_X_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast encoded labels back to a dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LabelEncoder() output is a numpy array, it's missing the index which is later used for\n",
    "concatanation of categorical, numercial and label data together. The following is a \n",
    "primitive solution but it works and there is no missalignment in the final df.\n",
    "\n",
    "\"\"\"\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "y_train.columns = ['labels']\n",
    "y_test.columns = ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "5       1\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       1"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Fully Paid\n",
       "1     Fully Paid\n",
       "2     Fully Paid\n",
       "3     Fully Paid\n",
       "4    Charged Off\n",
       "5     Fully Paid\n",
       "6     Fully Paid\n",
       "7     Fully Paid\n",
       "8     Fully Paid\n",
       "9     Fully Paid\n",
       "dtype: object"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(le.inverse_transform(y_train.values.ravel())).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking all the dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979767, 160)\n",
      "(326589, 160)\n"
     ]
    }
   ],
   "source": [
    "final_train = pd.concat([nmrcl_X_train,ctgrcl_X_train,y_train],axis=1)\n",
    "final_test = pd.concat([nmrcl_X_test,ctgrcl_X_test,y_test],axis=1)\n",
    "\n",
    "print(final_train.shape)\n",
    "print(final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979767, 141)\n"
     ]
    }
   ],
   "source": [
    "# it's a temporary measurement as there are no resources for sound binning\n",
    "# delete all the columns that contain single unique values\n",
    "for col in final_train.columns:\n",
    "    if len(final_train[col].unique()) == 1:\n",
    "        final_train.drop(col,inplace=True,axis=1)\n",
    "print(final_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = final_train.columns\n",
    "final_train = final_train[columns]\n",
    "final_test = final_test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_csv('Data/train.csv',index=False)\n",
    "final_test.to_csv('Data/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
